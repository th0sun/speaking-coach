# ü§ñ ‡∏£‡∏∞‡∏ö‡∏ö AI Speech Analysis - ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

## üìä Flow ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

```mermaid
graph TD
    A[üë§ User ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Record] --> B[üé§ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á]
    B --> C[üó£Ô∏è Speech Recognition<br/>‡∏ü‡∏±‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
    C --> D[üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á Transcript<br/>‡∏û‡∏£‡πâ‡∏≠‡∏° Timestamp]
    D --> E[User ‡∏Å‡∏î‡∏´‡∏¢‡∏∏‡∏î]
    E --> F{‡∏°‡∏µ Transcript?}
    
    F -->|‡πÑ‡∏°‡πà‡∏°‡∏µ| G[‚ö†Ô∏è ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ transcript]
    F -->|‡∏°‡∏µ| H[üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Pauses<br/>‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞]
    
    H --> I[üì¶ ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•<br/>+ Timing + Pauses]
    I --> J[üì§ ‡∏™‡πà‡∏á‡πÑ‡∏õ Backend API<br/>localhost:5001/api/analyze]
    
    J --> K[üîê Backend ‡∏£‡∏±‡∏ö Request]
    K --> L[üåê Backend ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API<br/>gemini-3-flash-preview]
    L --> M[ü§ñ Gemini ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•]
    M --> N[üìä Gemini ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏±‡∏ö<br/>JSON format]
    
    N --> O[Backend ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö Frontend]
    O --> P[Frontend ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•<br/>Scores, Strengths, Issues]
    P --> Q[üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Session<br/>localStorage + Export JSON]
```

## üîç ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

### 1Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Recording)

**‡πÑ‡∏ü‡∏•‡πå:** `js/app.js` ‚Üí `startRecording()`

```javascript
// ‡∏Ç‡∏≠ permission ‡πÑ‡∏°‡∏Ñ‡πå
const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

// ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
const recorder = new MediaRecorder(stream);
recorder.start();

// ‡πÄ‡∏£‡∏¥‡πà‡∏° Speech Recognition ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
initializeSpeechRecognition();
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- üéµ ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á (blob) ‚Üí ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô `recordedBlob`
- üìù Transcript (text) ‚Üí ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô `transcript` array

---

### 2Ô∏è‚É£ Speech Recognition (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‚Üí‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)

**‡πÑ‡∏ü‡∏•‡πå:** `js/app.js` ‚Üí `initializeSpeechRecognition()`

```javascript
const recog = new SpeechRecognition();
recog.lang = 'th-TH';
recog.continuous = true;

recog.onresult = (event) => {
    // ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° real-time
    const text = event.results[i][0].transcript;
    
    // ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏û‡∏£‡πâ‡∏≠‡∏° timestamp
    transcriptSegments.push({
        text: text,
        startTime: 2.5,  // ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°
        endTime: 5.0     // ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏ö
    });
};
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
```javascript
[
  { text: "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", startTime: 0.0, endTime: 2.0 },
  { text: "‡∏ú‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏≤‡∏¢", startTime: 2.0, endTime: 4.5 },
  { text: "‡πÄ‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå", startTime: 4.5, endTime: 6.0 }
]
```

---

### 3Ô∏è‚É£ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Pauses & Timing

**‡πÑ‡∏ü‡∏•‡πå:** `js/app.js` ‚Üí `AICoach.analyzeSpeech()`

```javascript
// ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì pause ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á segments
const pauseDuration = nextSeg.startTime - currentSeg.endTime;

if (pauseDuration > 0.5) {  // ‡∏´‡∏¢‡∏∏‡∏î‡∏ô‡∏≤‡∏ô‡∏Å‡∏ß‡πà‡∏≤ 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
    pauses.push({
        after: "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö...",
        duration: 1.2,
        position: "2.0s"
    });
}

// ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö transcript
const formatted = `
[0.0s-2.0s] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
[PAUSE 1.2s]
[3.2s-4.5s] ‡∏ú‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏≤‡∏¢
`;

// ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
const stats = {
    speakingTime: 15.5,    // ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡∏à‡∏£‡∏¥‡∏á
    pauseTime: 4.5,        // ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏∏‡∏î
    wordsPerMinute: 120    // ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
};
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:** Transcript ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• timing ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô

---

### 4Ô∏è‚É£ ‡∏™‡πà‡∏á‡πÑ‡∏õ Backend API

**‡πÑ‡∏ü‡∏•‡πå:** `js/app.js` ‚Üí `AICoach.analyzeSpeech()`

```javascript
// ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI
const prompt = `
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏Ñ‡πâ‡∏ä‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

**‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î (‡∏°‡∏µ timestamp):**
[0.0s-2.0s] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
[PAUSE 1.2s]
[3.2s-4.5s] ‡∏ú‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏≤‡∏¢

**‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î:**
- ‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏à‡∏£‡∏¥‡∏á: 15.5s (77%)
- ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å: 4.5s (23%)
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: 120 ‡∏Ñ‡∏≥/‡∏ô‡∏≤‡∏ó‡∏µ

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô JSON...
`;

// ‡∏™‡πà‡∏á‡πÑ‡∏õ backend
const response = await fetch('http://localhost:5001/api/analyze', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ prompt: prompt })
});
```

---

### 5Ô∏è‚É£ Backend ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•

**‡πÑ‡∏ü‡∏•‡πå:** `backend/server.py` ‚Üí `/api/analyze`

```python
@app.route('/api/analyze', methods=['POST'])
def analyze():
    # ‡∏£‡∏±‡∏ö prompt ‡∏à‡∏≤‡∏Å frontend
    data = request.json
    prompt = data.get('prompt')
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API (‡πÉ‡∏ä‡πâ API key ‡∏à‡∏≤‡∏Å .env)
    response = requests.post(
        f'https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent?key={GEMINI_API_KEY}',
        json={
            'contents': [{
                'parts': [{'text': prompt}]
            }]
        }
    )
    
    # ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö frontend
    return jsonify(response.json())
```

**‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Backend?**
- üîí **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** API key ‡∏ã‡πà‡∏≠‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô backend ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ user ‡πÄ‡∏´‡πá‡∏ô
- üõ°Ô∏è **CORS:** ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ cross-origin requests
- üìä **Monitoring:** ‡∏î‡∏π logs ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢

---

### 6Ô∏è‚É£ Gemini AI ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•

**‡∏ó‡∏µ‡πà Google Cloud:**

```
1. Gemini ‡∏≠‡πà‡∏≤‡∏ô prompt (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° + timestamp + stats)
2. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:
   - ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ (structure, clarity)
   - ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î (pace)
   - ‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å (pauses)
   - ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î (cognitive patterns)
3. ‡∏™‡∏£‡πâ‡∏≤‡∏á JSON response
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (JSON):**
```json
{
  "sentences": [...],
  "structure": { "score": 7 },
  "pace": {
    "overall": "‡∏û‡∏≠‡∏î‡∏µ",
    "paceScore": 8,
    "paceIssues": ["‡∏û‡∏π‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÅ‡∏£‡∏Å"]
  },
  "pauses": {
    "totalPauses": 5,
    "pauseScore": 7,
    "appropriatePauses": ["‡∏´‡∏•‡∏±‡∏á‡∏à‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"],
    "inappropriatePauses": ["‡∏Å‡∏•‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"]
  },
  "scores": {
    "fluency": 7,
    "clarity": 8,
    "pace": 8,
    "pauses": 7,
    "overall": 7.5
  },
  "strengths": ["‡∏û‡∏π‡∏î‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô", "‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á"],
  "improvements": ["‡∏Ñ‡∏ß‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á"]
}
```

---

### 7Ô∏è‚É£ Frontend ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•

**‡πÑ‡∏ü‡∏•‡πå:** `js/app.js` ‚Üí UI Components

```javascript
// ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏à‡∏≤‡∏Å API
const feedback = await aiCoach.analyzeSpeech(...);

// ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
setAiFeedback(feedback);

// ‡πÅ‡∏™‡∏î‡∏á UI:
// - Scores: fluency, clarity, pace, pauses
// - Strengths ‚úÖ
// - Improvements ‚ö†Ô∏è
// - Next Steps üìù
```

---

## üéØ ‡∏™‡∏£‡∏∏‡∏õ‡∏á‡πà‡∏≤‡∏¢‡πÜ

| ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô | ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ | ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå |
|---------|--------|---------|
| 1. Record | ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á + Speech Recognition | ‡πÄ‡∏™‡∏µ‡∏¢‡∏á + transcript |
| 2. Analyze Timing | ‡∏´‡∏≤ pauses + ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß | Transcript ‡∏û‡∏£‡πâ‡∏≠‡∏° timing |
| 3. Format Prompt | ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• | Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI |
| 4. Send to Backend | ‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô API (‡∏ã‡πà‡∏≠‡∏ô API key) | Request ‡πÑ‡∏õ Gemini |
| 5. Gemini Process | AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î | JSON results |
| 6. Display Results | ‡πÅ‡∏™‡∏î‡∏á scores + feedback | UI ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• |

## üí° ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

### ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö
- **‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** API key ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô backend
- **‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥:** ‡∏°‡∏µ timing + pause detection
- **‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô:** ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ + ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞
- **Modular:** ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

### ‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î
- **Speech Recognition:** ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ 100%
- **‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:** Speech Recognition ‡∏≠‡∏≤‡∏à‡∏û‡∏•‡∏≤‡∏î‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥
- **Quota:** Free tier Gemini ‡∏°‡∏µ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î
- **Text-based:** AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å text ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á

## üîß ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

```
Speaking_improve/
‚îú‚îÄ‚îÄ js/app.js              ‚Üê ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö (1,721 lines)
‚îÇ   ‚îú‚îÄ‚îÄ startRecording()         ‚Üí ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
‚îÇ   ‚îú‚îÄ‚îÄ initializeSpeechRecognition() ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‚Üí‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
‚îÇ   ‚îú‚îÄ‚îÄ AICoach.analyzeSpeech()  ‚Üí ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå + ‡∏™‡πà‡∏á API
‚îÇ   ‚îî‚îÄ‚îÄ UI Components            ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
‚îÇ
‚îú‚îÄ‚îÄ backend/server.py      ‚Üê API Proxy
‚îÇ   ‚îî‚îÄ‚îÄ /api/analyze       ‚Üí ‡∏£‡∏±‡∏ö prompt, ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini
‚îÇ
‚îî‚îÄ‚îÄ backend/.env           ‚Üê API Key (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢!)
    ‚îú‚îÄ‚îÄ GEMINI_API_KEY
    ‚îî‚îÄ‚îÄ GEMINI_MODEL=gemini-3-flash-preview
```

---

‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π code ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ï‡∏£‡∏á‡πÑ‡∏´‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ö‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö! üöÄ
