/**
 * üõ†Ô∏è Speaking Coach Pro - Shared Modules
 * Contains: Config, Helpers, AudioAnalyzer, AICoach
 */

const isLocal = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1';

// ==========================================
// 1. CONFIGURATION
// ==========================================
const CONFIG = {
    // Backend API URL (Auto-switch between Local and Production)
    BACKEND_URL: isLocal ? 'http://localhost:5001' : 'https://speaking-coach.onrender.com',

    // Default AI Model
    GEMINI_MODEL: 'gemini-3-flash-preview', // Gemini 3 Flash Preview (Fastest)

    // Available Models
    AVAILABLE_MODELS: [
        // Gemini 3 Series (Preview - Latest)
        { id: 'gemini-3-flash-preview', name: 'Gemini 3 Flash Preview (Fastest + Accurate)', type: 'preview' },
        { id: 'gemini-3-pro-preview', name: 'Gemini 3 Pro Preview (Best Reasoning)', type: 'preview' },

        // Gemini 2.5 Series (Stable - Production)
        { id: 'gemini-2.5-flash', name: 'Gemini 2.5 Flash (Stable)', type: 'production' },
        { id: 'gemini-2.5-pro', name: 'Gemini 2.5 Pro (Enterprise)', type: 'production' },
        { id: 'gemini-2.5-flash-lite', name: 'Gemini 2.5 Flash Lite (Cost Efficient)', type: 'lite' },
        { id: 'gemini-2.5-flash-live', name: 'Gemini 2.5 Flash Live (Voice/Video)', type: 'production' },

        // Gemini 1.5 Series (Legacy)
        { id: 'gemini-1.5-flash', name: 'Gemini 1.5 Flash (Legacy)', type: 'legacy' },
        { id: 'gemini-1.5-pro', name: 'Gemini 1.5 Pro (Legacy)', type: 'legacy' }
    ],

    // App settings
    APP_VERSION: '3.7',
    APP_NAME: 'Speaking Coach Pro',

    // Debug mode
    DEBUG: true,

    // LocalStorage keys
    STORAGE_KEYS: {
        API_KEY: 'gemini_api_key',
        CURRENT_DAY: 'current_day',
        SESSIONS: 'sessions',
        ACHIEVEMENTS: 'achievements'
    }
};

// Export for use in other files
window.CONFIG = CONFIG;

if (typeof module !== 'undefined' && module.exports) {
    module.exports = CONFIG;
}

// ==========================================
// 2. HELPER FUNCTIONS
// ==========================================

// Helper: Convert Blob to Base64
window.convertBlobToBase64 = async function (blob) {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            const base64 = reader.result.split(',')[1]; // Remove data:audio/webm;base64, prefix
            resolve(base64);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
    });
};

// Helper: Calculate Streak
window.calculateStreak = function (sessions) {
    if (!sessions || sessions.length === 0) return 0;

    const today = new Date();
    today.setHours(0, 0, 0, 0);

    let streak = 0;
    let checkDate = new Date(today);

    for (let i = sessions.length - 1; i >= 0; i--) {
        const sessionDate = new Date(sessions[i].date);
        sessionDate.setHours(0, 0, 0, 0);

        if (sessionDate.getTime() === checkDate.getTime()) {
            streak++;
            checkDate.setDate(checkDate.getDate() - 1);
        } else if (sessionDate.getTime() < checkDate.getTime()) {
            break;
        }
    }

    return streak;
};

// ==========================================
// 3. AUDIO ANALYZER SERVICE
// ==========================================

class AudioAnalyzer {
    constructor() {
        this.audioContext = null;
        this.analyser = null;
        this.source = null;
        this.dataArray = null;
        this.isAnalyzing = false;
        this.stats = {
            volume: { min: Infinity, max: -Infinity, sum: 0, count: 0 },
            pitch: { min: Infinity, max: -Infinity, sum: 0, count: 0 }
        };
        this.animationFrame = null;
    }

    start(stream) {
        try {
            const AudioContext = window.AudioContext || window.webkitAudioContext;
            this.audioContext = new AudioContext();
            this.analyser = this.audioContext.createAnalyser();
            this.source = this.audioContext.createMediaStreamSource(stream);
            this.source.connect(this.analyser);

            this.analyser.fftSize = 2048;
            this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);

            this.isAnalyzing = true;
            this.resetStats();
            this.analyze();

            console.log("üîä Audio Analyzer started");
        } catch (e) {
            console.error("‚ùå Failed to start Audio Analyzer:", e);
        }
    }

    resetStats() {
        this.stats = {
            volume: { min: Infinity, max: -Infinity, sum: 0, count: 0 },
            pitch: { min: Infinity, max: -Infinity, sum: 0, count: 0 }
        };
    }

    analyze() {
        if (!this.isAnalyzing) return;
        this.animationFrame = requestAnimationFrame(() => this.analyze());

        this.analyser.getByteTimeDomainData(this.dataArray);

        // --- Calculate Volume (RMS) ---
        let sum = 0;
        for (let i = 0; i < this.dataArray.length; i++) {
            const x = (this.dataArray[i] - 128) / 128.0;
            sum += x * x;
        }
        const rms = Math.sqrt(sum / this.dataArray.length);
        const db = 20 * Math.log10(rms + 1e-10); // dB

        // Update Volume stats
        if (isFinite(db) && db > -100) {
            this.stats.volume.max = Math.max(this.stats.volume.max, db);
            this.stats.volume.min = Math.min(this.stats.volume.min, db);
            this.stats.volume.sum += db;
            this.stats.volume.count++;
        }

        // --- Simple Pitch Estimation (Zero Crossing Rate) ---
        let zeroCrossings = 0;
        for (let i = 1; i < this.dataArray.length; i++) {
            if ((this.dataArray[i] - 128) > 0 && (this.dataArray[i - 1] - 128) <= 0) {
                zeroCrossings++;
            }
        }

        const estimatedPitch = (zeroCrossings / this.dataArray.length) * (this.audioContext.sampleRate / 2);

        if (estimatedPitch > 50 && estimatedPitch < 1000) { // Human voice range filter
            this.stats.pitch.max = Math.max(this.stats.pitch.max, estimatedPitch);
            this.stats.pitch.min = Math.min(this.stats.pitch.min, estimatedPitch);
            this.stats.pitch.sum += estimatedPitch;
            this.stats.pitch.count++;
        }
    }

    stop() {
        this.isAnalyzing = false;
        if (this.animationFrame) cancelAnimationFrame(this.animationFrame);

        if (this.audioContext) {
            this.audioContext = null;
        }
        console.log("üîá Audio Analyzer stopped");
    }

    getStats() {
        const volAvg = this.stats.volume.count ? (this.stats.volume.sum / this.stats.volume.count) : -100;
        const pitchAvg = this.stats.pitch.count ? (this.stats.pitch.sum / this.stats.pitch.count) : 0;

        return {
            volume: {
                avg: volAvg.toFixed(1),
                max: this.stats.volume.max !== -Infinity ? this.stats.volume.max.toFixed(1) : -100,
                min: this.stats.volume.min !== Infinity ? this.stats.volume.min.toFixed(1) : -100
            },
            pitch: {
                avg: pitchAvg.toFixed(0),
                max: this.stats.pitch.max !== -Infinity ? this.stats.pitch.max.toFixed(0) : 0,
                min: this.stats.pitch.min !== Infinity ? this.stats.pitch.min.toFixed(0) : 0
            }
        };
    }
}

// Expose to window
window.AudioAnalyzer = AudioAnalyzer;

// ==========================================
// 4. AI COACH SERVICE
// ==========================================

class AICoach {
    constructor() {
        this.backendURL = CONFIG.BACKEND_URL;
    }

    async analyzeSpeech(apiKey, audioBlob, transcript, duration, weekData, topicData, sessions = [], audioStats = null, model = CONFIG.GEMINI_MODEL) {
        // Handle transcript properly with TIMING information
        let transcriptText = '';
        let timingInfo = '';
        let pauseAnalysis = '';

        if (!transcript || (Array.isArray(transcript) && transcript.length === 0)) {
            transcriptText = '[‡πÑ‡∏°‡πà‡∏°‡∏µ transcript - Speech Recognition ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô]';
            console.warn('‚ö†Ô∏è No transcript available for AI analysis');
        } else if (Array.isArray(transcript)) {
            // Build transcript with timing + pause detection
            const segments = [];
            const pauses = [];

            transcript.forEach((seg, index) => {
                const startSec = seg.startTime?.toFixed(1) || '0.0';
                const endSec = seg.endTime?.toFixed(1) || '0.0';

                // Add segment with timestamp
                segments.push(`[${startSec}s-${endSec}s] ${seg.text}`);

                // Detect pause before next segment
                if (index < transcript.length - 1) {
                    const nextSeg = transcript[index + 1];
                    const pauseDuration = (nextSeg.startTime || 0) - (seg.endTime || 0);

                    if (pauseDuration > 0.5) { // Pause > 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                        pauses.push({
                            after: seg.text.substring(0, 30) + '...',
                            duration: pauseDuration.toFixed(1),
                            position: `${endSec}s`
                        });
                        segments.push(`[PAUSE ${pauseDuration.toFixed(1)}s]`);
                    }
                }
            });

            transcriptText = segments.join('\n');

            // Summary of pauses
            if (pauses.length > 0) {
                pauseAnalysis = `\n**‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å (${pauses.length} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á):**\n` +
                    pauses.map(p => `- ‡∏´‡∏•‡∏±‡∏á "${p.after}" ‡∏´‡∏¢‡∏∏‡∏î ${p.duration}s (‡∏ó‡∏µ‡πà ${p.position})`).join('\n');
            }

            // Timing summary
            const totalDuration = transcript[transcript.length - 1]?.endTime || duration;
            const speakingTime = transcript.reduce((sum, seg) => {
                return sum + ((seg.endTime || 0) - (seg.startTime || 0));
            }, 0);
            const pauseTime = totalDuration - speakingTime;

            timingInfo = `\n**‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î:**
- ‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏à‡∏£‡∏¥‡∏á: ${speakingTime.toFixed(1)}s (${(speakingTime / totalDuration * 100).toFixed(0)}%)
- ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å: ${pauseTime.toFixed(1)}s (${(pauseTime / totalDuration * 100).toFixed(0)}%)
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: ${(transcript.join(' ').split(' ').length / (speakingTime / 60)).toFixed(0)} ‡∏Ñ‡∏≥/‡∏ô‡∏≤‡∏ó‡∏µ`;
        } else {
            transcriptText = String(transcript);
        }

        // ‚ú® Build previous feedback for progress comparison
        let previousFeedback = '';

        if (sessions && sessions.length > 0) {
            const recentSessions = sessions
                .filter(s => s.aiFeedback) // ‡∏°‡∏µ AI feedback
                .slice(-3)                  // ‡πÄ‡∏≠‡∏≤ 3 sessions ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                .reverse();                 // ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô

            if (recentSessions.length > 0) {
                previousFeedback = `\n**üìä ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ (${recentSessions.length} sessions ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î):**\n\n`;

                recentSessions.forEach((session, index) => {
                    const fb = session.aiFeedback;
                    const sessionNum = recentSessions.length - index;

                    previousFeedback += `### Session ${sessionNum} (Day ${session.day}):
- Overall Score: ${fb.scores.overall}/10
- ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á: ${fb.strengths.slice(0, 2).join(', ')}
- ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: ${fb.improvements.slice(0, 2).join(', ')}
- Pace: ${fb.pace?.overall || 'N/A'} (${fb.scores.pace || 'N/A'}/10)
- Pauses: ${fb.pauses?.totalPauses || 0} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (${fb.scores.pauses || 'N/A'}/10)
- Root Cause: ${fb.rootCause?.primaryIssue || 'N/A'}

`;
                });

                previousFeedback += `\n**üéØ ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ù‡πâ‡∏≤‡∏î‡∏π:**
- ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ${recentSessions[0].aiFeedback.improvements.join(', ')}
- Root cause ‡πÄ‡∏î‡∏¥‡∏°: ${recentSessions[0].aiFeedback.rootCause?.primaryIssue}
`;
            }
        }

        // üéôÔ∏è Audio Handling
        let audioPart = null;
        if (audioBlob) {
            try {
                console.log('üéôÔ∏è Converting audio blob to base64...');
                const audioBase64 = await window.convertBlobToBase64(audioBlob);
                audioPart = {
                    inline_data: {
                        mime_type: "audio/webm",
                        data: audioBase64
                    }
                };
                console.log('‚úÖ Audio ready for analysis');
            } catch (err) {
                console.error('‚ùå Failed to convert audio:', err);
            }
        }

        // üîä Audio Stats Integration
        let audioStatsText = '';
        if (audioStats) {
            audioStatsText = `\n**üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Audio Signal Metrics):**
- Volume (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏á): Avg ${audioStats.volume.avg}dB (Max ${audioStats.volume.max}dB)
   *‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á -20dB ‡∏ñ‡∏∂‡∏á -10dB. ‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ -30dB ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ö‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ*
- Pitch (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏á): Avg ${audioStats.pitch.avg}Hz (Range ${audioStats.pitch.min}-${audioStats.pitch.max}Hz)
- Confidence (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°): ${audioStats.confidence}%
`;
        }

        const prompt = `‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏Ñ‡πâ‡∏ä‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å**‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á**‡πÅ‡∏•‡∏∞ Transcript:

**‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠:** ${topicData.title} - ${topicData.desc}
**‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏ô‡∏µ‡πâ:** ${weekData.goal}
**‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤:** ${Math.floor(duration / 60)} ‡∏ô‡∏≤‡∏ó‡∏µ ${duration % 60} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Audio Data):**
1. **‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Tone):** ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥, ‡∏û‡∏•‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
2. **‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞ (Pace):** ‡∏ü‡∏±‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ß‡πà‡∏≤‡πÄ‡∏£‡πá‡∏ß/‡∏ä‡πâ‡∏≤/‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
3. **‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î (Pauses):** ‡∏ü‡∏±‡∏á Dead Air ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÑ‡∏´‡∏°
4. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (Clarity):** ‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏£.‡πÄ‡∏£‡∏∑‡∏≠ ‡∏•.‡∏•‡∏¥‡∏á ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏Ñ‡∏ß‡∏ö‡∏Å‡∏•‡πâ‡∏≥
5. **‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (Emotion):** ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏´‡∏°
6. **‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Signal Quality):** ‡∏î‡∏π‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤ Volume/Pitch ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡∏°‡∏≤ ‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

**‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î (Transcript ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á):**
${transcriptText}
${timingInfo}
${pauseAnalysis}
${audioStatsText}
${previousFeedback}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô JSON:

{
  "sentences": [
    {
      "text": "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î",
      "purpose": "‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå",
      "clarity": 7,
      "issues": ["‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö"]
    }
  ],
  "structure": {
    "hasIntro": true,
    "hasBody": true,
    "hasConclusion": false,
    "overallStructure": "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á",
    "score": 6
  },
  "pace": {
    "overall": "‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ/‡∏û‡∏≠‡∏î‡∏µ/‡∏ä‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ",
    "wordsPerMinute": 150,
    "paceScore": 7,
    "paceIssues": ["‡∏û‡∏π‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÅ‡∏£‡∏Å", "‡∏ä‡πâ‡∏≤‡∏•‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡πâ‡∏≤‡∏¢"]
  },
  "pauses": {
    "totalPauses": 5,
    "appropriatePauses": ["‡∏´‡∏•‡∏±‡∏á‡∏à‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ", "‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"],
    "inappropriatePauses": ["‡∏Å‡∏•‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ", "‡∏Ç‡∏ì‡∏∞‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏û‡∏π‡∏î"],
    "pauseScore": 6,
    "pauseIssues": ["‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡πà‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ", "‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏≠‡πÉ‡∏ô‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"]
  },
  "voiceQuality": { // NEW SECTION
    "volumeAnalysis": "‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°/‡πÄ‡∏ö‡∏≤‡πÑ‡∏õ/‡∏î‡∏±‡∏á‡πÑ‡∏õ",
    "pitchAnalysis": "‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥/Monotone/‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏π‡∏á‡πÑ‡∏õ",
    "suggestion": "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á"
  },
  "progression": {
    "comparedToPrevious": "‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô/‡πÅ‡∏¢‡πà‡∏•‡∏á/‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°/‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å",
    "improvements": [
      "‡πÅ‡∏Å‡πâ‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á X ‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß",
      "Pace ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô"
    ],
    "stillNeedWork": [
      "‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Y",
      "Pauses ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
    ],
    "progressScore": 8,
    "progressNote": "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πâ‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°"
  },
  "cognitivePatterns": {
    "thinkingStyle": "scattered/organized",
    "scopeControl": "expanding/controlled",
    "preparedness": "improvised/prepared",
    "issues": ["‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏¥‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏û‡∏π‡∏î", "‡∏Ç‡∏≤‡∏î scope ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"]
  },
  "rootCause": {
    "primaryIssue": "‡∏Ç‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô",
    "whyYouSpokeThatWay": "‡∏û‡∏π‡∏î‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏¥‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤",
    "deepInsights": ["insight1", "insight2"]
  },
  "scores": {
    "fluency": 7,
    "clarity": 6,
    "structure": 5,
    "pace": 7,
    "pauses": 6,
    "engagement": 7,
    "overall": 6.5
  },
  "strengths": ["‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á1", "‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á2", "‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á3"],
  "improvements": ["‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á1", "‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á2", "‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á3"],
  "nextSteps": "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"
}

‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
- **Prioritize Audio & Metrics:** ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (Volume/Pitch) ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ transcript
- ‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏µ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
- ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á intro-body-conclusion ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏Å timestamp** (‡πÄ‡∏£‡πá‡∏ß/‡∏ä‡πâ‡∏≤/‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠)
- **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å** (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°/‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°/‡∏ö‡πà‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô/‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô)
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô/‡∏Ñ‡∏¥‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏û‡∏π‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏à‡∏∂‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô
- **‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô pace ‡πÅ‡∏•‡∏∞ pauses ‡πÅ‡∏¢‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏≤‡∏Å**
${sessions && sessions.length > 0 ? `
- **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö sessions ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤** (‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô/‡πÅ‡∏¢‡πà‡∏•‡∏á/‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°)
- **‡∏ä‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡πâ‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á**
- **‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à‡∏ñ‡πâ‡∏≤‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏ó‡∏≥‡∏ú‡∏¥‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏ã‡πâ‡∏≥**
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô progressScore (0-10) ‡πÇ‡∏î‡∏¢‡∏î‡∏π‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
` : '- ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å ‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ'}`;

        try {
            console.log('ü§ñ Calling Analysis API...');
            console.log('üìä Audio Stats included:', audioStats);

            // Use backend API if audioBlob exists, otherwise call Gemini directly
            let response;

            if (audioBlob) {
                // Send to backend with audio file
                console.log('üì§ Sending audio to backend for analysis...');
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.webm');
                formData.append('prompt', prompt);

                response = await fetch(`${this.backendURL}/api/analyze`, {
                    method: 'POST',
                    body: formData
                });
            } else {
                // Fallback: Call Gemini API directly for text-only analysis
                console.log(`ü§ñ No audio - calling Gemini API directly (${model})...`);
                const endpoint = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;

                // Prepare Request Parts
                const parts = [];
                parts.push({ text: prompt });         // Add text prompt

                response = await fetch(endpoint, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{
                            parts: parts
                        }]
                    })
                });
            }

            if (!response.ok) {
                console.error('‚ùå Gemini API Error:', response.status, response.statusText);
                const errorData = await response.json();
                console.error('Error details:', errorData);

                if (response.status === 404) {
                    alert('‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Model ‡∏ô‡∏µ‡πâ (404) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô config.js');
                } else if (response.status === 429) {
                    alert('‚ö†Ô∏è ‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏ï‡πá‡∏° (429) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà');
                } else {
                    alert(`‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å AI (${response.status}): ‡πÄ‡∏ä‡πá‡∏Ñ API Key ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á`);
                }
                return null;
            }

            const data = await response.json();

            // Check for direct backend response format or Gemini original format
            if (data.analysis) return data.analysis; // Backend simplified response if applicable

            if (!data.candidates || !data.candidates[0]) {
                console.error('‚ö†Ô∏è No valid response from API');
                return null;
            }

            const text = data.candidates[0].content.parts[0].text;

            // Extract JSON from response
            const jsonMatch = text.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                return JSON.parse(jsonMatch[0]);
            }

            console.error('‚ö†Ô∏è No valid JSON found in AI response');
            return null;
        } catch (error) {
            console.error('‚ùå AI Analysis Error:', error);
            alert('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI');
            return null;
        }
    }
}

// Expose to window
window.AICoach = AICoach;
